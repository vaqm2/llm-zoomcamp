{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39180ce-334c-4f68-a50c-7b7dae7f7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65aa867-8c3f-4cd4-840f-bae016ed72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9865e4bd-109e-4582-9983-ae0e15a98a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=\"Which models are available from the google genai client?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8510c3d-f1e1-472d-972e-ac0c407d1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `google.generativeai` client (often imported as `genai`) provides access to Google's various generative AI models. The exact list of models available can vary slightly depending on your region, project settings, and any ongoing updates from Google.\n",
      "\n",
      "However, the most common and widely available models you'll find are:\n",
      "\n",
      "1.  **Gemini Models (Recommended for new development):** These are Google's latest and most capable models.\n",
      "\n",
      "    *   **`gemini-pro`**:\n",
      "        *   **Capabilities:** Generates text, handles multi-turn conversations (chat), and can perform complex reasoning tasks. It's the general-purpose, text-only Gemini model.\n",
      "        *   **Alias:** Sometimes referred to as `generative-model` (an alias for `gemini-pro`).\n",
      "\n",
      "    *   **`gemini-pro-vision`**:\n",
      "        *   **Capabilities:** A multimodal model that accepts both text and image input. It's excellent for understanding and generating content based on visual information combined with natural language instructions.\n",
      "        *   **Alias:** Sometimes referred to as `gemini-pro-vision` (no distinct alias usually).\n",
      "\n",
      "    *   **`gemini-1.5-pro-latest`**:\n",
      "        *   **Capabilities:** A significantly more powerful and efficient multimodal model, known for its massive context window (up to 1 million tokens), advanced reasoning, and native multimodal understanding (text, images, audio, video). The `-latest` suffix means it points to the most stable and up-to-date minor version of Gemini 1.5 Pro.\n",
      "        *   **Note:** Access to 1.5 models might be through specific regions or require opting into certain features, and there might be more specific version names (e.g., `gemini-1.5-pro-001`).\n",
      "\n",
      "    *   **`gemini-1.5-flash-latest`**:\n",
      "        *   **Capabilities:** A lighter-weight and faster version of Gemini 1.5, optimized for speed and cost-efficiency while still retaining a large context window and multimodal capabilities. Ideal for high-volume, lower-latency tasks.\n",
      "\n",
      "2.  **Embedding Models:**\n",
      "\n",
      "    *   **`embedding-001`**:\n",
      "        *   **Capabilities:** Used to convert text into numerical vector representations (embeddings). These embeddings capture the semantic meaning of the text and are crucial for tasks like semantic search, recommendation systems, and clustering.\n",
      "        *   **Alias:** Sometimes referred to as `text-embedding-004` (an alias for `embedding-001`).\n",
      "\n",
      "3.  **PaLM 2 Models (Legacy / Older Generation):** While still available for backward compatibility, Gemini models are generally recommended for new projects due to their enhanced capabilities.\n",
      "\n",
      "    *   **`text-bison-001`**:\n",
      "        *   **Capabilities:** A text generation model from the PaLM 2 family. Good for general text completion, summarization, and content creation.\n",
      "\n",
      "    *   **`chat-bison-001`**:\n",
      "        *   **Capabilities:** A chat-optimized model from the PaLM 2 family, designed for multi-turn conversations.\n",
      "\n",
      "### How to List Available Models Programmatically\n",
      "\n",
      "The best way to see the *exact* models available to you is to use the `list_models()` function:\n",
      "\n",
      "```python\n",
      "import google.generativeai as genai\n",
      "\n",
      "# Configure your API key\n",
      "# genai.configure(api_key=\"YOUR_API_KEY\") \n",
      "# (Or set GOOGLE_API_KEY environment variable)\n",
      "\n",
      "try:\n",
      "    for m in genai.list_models():\n",
      "        print(f\"Name: {m.name}\")\n",
      "        print(f\"Description: {m.description}\")\n",
      "        print(f\"Supported Generation Methods: {m.supported_generation_methods}\")\n",
      "        print(\"-\" * 30)\n",
      "except Exception as e:\n",
      "    print(f\"Error listing models: {e}\")\n",
      "    print(\"Please ensure your API key is correctly configured and has access.\")\n",
      "\n",
      "```\n",
      "\n",
      "This code snippet will output details for each model, including its full name (e.g., `models/gemini-pro`), a description, and crucially, `supported_generation_methods` (e.g., `['generateContent']`, `['embedContent']`), which tells you what the model can do.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
